{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2633196-d75f-4876-9933-b34bc9c08522",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python whisperPrepWavs.py --WavFolder PathToYourFolder\n",
    "\n",
    "# WARNING!!! This notebook is NOT user friendly or well documented.\n",
    "# We don't have time, resources, and many experiments are still underway. \n",
    "# The times we live in, the extreme competition, the open source movement seems to be dying, \n",
    "# Really makes you wonder. So yeah... Whoever can read the code and design intent, this is christmas enough already.\n",
    "# As Ellen from the Witch's House says... people are only kind when they can afford to be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeed934-03e6-4f82-a346-f8835a0701f8",
   "metadata": {},
   "source": [
    "# Dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603b853-974e-4785-aad4-621577fc45ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Anyone else should probably change this to 0 if they only have one GPU. \n",
    "# We're only putting it on our secondary GPU since it has alot of VRAM. Training this thing takes ALOT of VRAM.\n",
    "#Maybe we should give the authors the benefit of the doubt. Maybe it's not gatekeeping.\n",
    "# Maybe it's not so much the intense desperate competition for an edge in this post-job world taken over by AI.\n",
    "# Maybe the reason training code isn't being released is... \n",
    "# there is no way the average person is training this on their consumer GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "import librosa\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import SeamlessM4TFeatureExtractor, Wav2Vec2BertModel\n",
    "from langid import classify\n",
    "from utils.util import load_config\n",
    "from maskgct.g2p.g2p_generation import g2p, chn_eng_g2p\n",
    "from models.codec.kmeans.repcodec_model import RepCodec\n",
    "\n",
    "from pytorch_optimizer import AdamW# Pick an optimizer. any optimizer. Well.. not ANY, but you get the idea\n",
    "\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import LangLib\n",
    "\n",
    "# Choose an appropriate Whisper model size based on your computational resources\n",
    "#model_name = \"openai/whisper-base\"  # Options: tiny, base, small, medium, large\n",
    "#whisper_processor = WhisperProcessor.from_pretrained(model_name)\n",
    "#whisper_model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "#whisper_model.eval()\n",
    "#whisper_model.to(device)\n",
    "\n",
    "#EDIT: Yeah, we're running the whisper stage separately. To conserve VRAM. \n",
    "# (In fact, don't bother using whisper during inferencing. Just type out the reference text yourself. )\n",
    "# Otherwise you will not have enough VRAM\n",
    "\n",
    "DatasetDir = \"./Dataset/\"\n",
    "input_text_file = DatasetDir + \"newbark-train.txt\"\n",
    "\n",
    "# Initialize necessary models and processors\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load processor\n",
    "processor = SeamlessM4TFeatureExtractor.from_pretrained(\"./w2v-bert-2.0\")\n",
    "# Load semantic model\n",
    "semantic_model = Wav2Vec2BertModel.from_pretrained(\"./w2v-bert-2.0\")\n",
    "semantic_model.eval()\n",
    "semantic_model.to(device)\n",
    "\n",
    "# Load semantic mean and std\n",
    "stat_mean_var = torch.load(\"./maskgct/ckpt/wav2vec2bert_stats.pt\")\n",
    "semantic_mean = stat_mean_var[\"mean\"].to(device)\n",
    "semantic_std = torch.sqrt(stat_mean_var[\"var\"]).to(device)\n",
    "\n",
    "# Load semantic codec\n",
    "cfg_path = \"./maskgct/config/maskgct.json\"\n",
    "cfg = load_config(cfg_path)\n",
    "semantic_codec = RepCodec(cfg=cfg.model.semantic_codec)\n",
    "semantic_codec.eval()\n",
    "semantic_codec.to(device)\n",
    "# Load semantic codec checkpoint\n",
    "semantic_codec_ckpt = \"./ckpt/MaskGCT/semantic_codec/model.safetensors\"\n",
    "import safetensors\n",
    "safetensors.torch.load_model(semantic_codec, semantic_codec_ckpt)\n",
    "\n",
    "# G2P functions\n",
    "def detect_text_language(text):\n",
    "    return classify(text)[0]\n",
    "\n",
    "def g2p_(text, language):\n",
    "    if language in [\"zh\", \"en\"]:\n",
    "        return chn_eng_g2p(text)\n",
    "    else:\n",
    "        return g2p(text=text, sentence=None, language=language)\n",
    "\n",
    "\n",
    "import json\n",
    " \n",
    "        \n",
    "def update_vocab(new_phonemes, vocab_file_path=\"./vocab.json\"):\n",
    "    # Load the existing vocab file\n",
    "    with open(vocab_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    vocab = data.get('vocab', {})\n",
    "    \n",
    "    # Get the maximum index value in the vocab\n",
    "    if vocab:\n",
    "        max_index = max(vocab.values())\n",
    "    else:\n",
    "        max_index = -1  # Start from 0 if vocab is empty\n",
    "    \n",
    "    # For each new phoneme, add it to the vocab if not present\n",
    "    for phoneme in new_phonemes:\n",
    "        if phoneme not in vocab.keys():\n",
    "            max_index += 1\n",
    "            vocab[phoneme] = max_index\n",
    "    \n",
    "    # Update the data\n",
    "    data['vocab'] = vocab\n",
    "    \n",
    "    # Write back to the file\n",
    "    with open(vocab_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def checkPhonemeList(IPAlist, vocab_file_path=\"./vocab.json\"):\n",
    "    not_in_vocab = set()\n",
    "\n",
    "    with open(vocab_file_path, 'r', encoding='utf-8') as f:\n",
    "        #print(f.read())\n",
    "        f.seek(0)  # Reset file pointer to beginning\n",
    "        vocab_data = json.load(f)\n",
    "\n",
    "    vocabIPAs = list(vocab_data['vocab'].keys())\n",
    "    for IPAchar in IPAlist:\n",
    "        if IPAchar not in vocabIPAs:\n",
    "            not_in_vocab.add(IPAchar)\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    if len(not_in_vocab) > 0:\n",
    "        print(f\"The following characters are not in the vocabulary: {', '.join(not_in_vocab)}\")\n",
    "        update_vocab(not_in_vocab)\n",
    "\n",
    "\n",
    "def phoneme2token(phonemes, vocab_file_path=\"./vocab.json\"):\n",
    "        tokens = []\n",
    "\n",
    "        with open(vocab_file_path, 'r') as f:\n",
    "            #print(f.read())\n",
    "            f.seek(0)  # Reset file pointer to beginning\n",
    "            vocab_data = json.load(f)\n",
    "\n",
    "        vocab = vocab_data[\"vocab\"]\n",
    "    \n",
    "        if isinstance(phonemes, list):\n",
    "            for phone in phonemes:\n",
    "                phone = phone.split(\"\\t\")[0]\n",
    "                phonemes_split = phone.split(\"|\")\n",
    "                tokens.append(\n",
    "                    [vocab[p] for p in phonemes_split if p in vocab.keys()]\n",
    "                )\n",
    "        else:\n",
    "            phonemes = phonemes.split(\"\\t\")[0]\n",
    "            phonemes_split = phonemes.split(\"|\")\n",
    "            tokens = [vocab[p] for p in phonemes_split if p in vocab.keys()]\n",
    "\n",
    "        f.close()\n",
    "        return tokens\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_semantic_code(semantic_mean, semantic_std, speech_16k):\n",
    "    # Extract features\n",
    "    inputs = processor(speech_16k, sampling_rate=16000, return_tensors=\"pt\")\n",
    "    input_features = inputs[\"input_features\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "    # Get embeddings\n",
    "    vq_emb = semantic_model(\n",
    "        input_features=input_features,\n",
    "        attention_mask=attention_mask,\n",
    "        output_hidden_states=True,\n",
    "    )\n",
    "    feat = vq_emb.hidden_states[17]  # (B, T, C)\n",
    "    feat = (feat - semantic_mean) / semantic_std\n",
    "\n",
    "    # Quantize to get semantic codes\n",
    "    semantic_code, _ = semantic_codec.quantize(feat)  # (B, T)\n",
    "    semantic_code = semantic_code.squeeze(0)  # Remove batch dimension\n",
    "\n",
    "    return semantic_code.cpu().numpy()  # Convert to numpy array for saving\n",
    "    \n",
    "\n",
    "# Main dataset preparation function\n",
    "def prepare_dataset(input_text_file, output_csv_file, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Open the CSV file for writing\n",
    "    with open(output_csv_file, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        # Write header\n",
    "        csv_writer.writerow(['phoneme_ids', 'semantic_code_path'])\n",
    "\n",
    "        # Read the input text file\n",
    "        with open(input_text_file, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "            for line in tqdm(lines):\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue  # Skip empty lines\n",
    "                try:\n",
    "                    audio_path, transcript = line.split('|')\n",
    "                except ValueError:\n",
    "                    print(f\"Line format incorrect: {line}\")\n",
    "                    continue\n",
    "\n",
    "                if \"]Â¶[\" in line:\n",
    "                    continue\n",
    "\n",
    "                # Load audio\n",
    "                speech_16k, _ = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "                # Detect language\n",
    "                #language = detect_text_language(transcript)\n",
    "                #if language not in [\"en\", \"zh\", \"ja\", \"ko\", \"fr\", \"de\", \"vi\"]:\n",
    "                #    print(f\"Unsupported language '{language}' for transcript: {transcript}\")\n",
    "                #    continue\n",
    "\n",
    "                language = \"en\"\n",
    "                if LangLib.isCN(transcript):\n",
    "                    language = \"zh\"\n",
    "\n",
    "                if LangLib.isJaptxt(transcript):\n",
    "                    language = \"ja\"\n",
    "\n",
    "                if LangLib.isViet(transcript):\n",
    "                    language = \"vi\"\n",
    "                                \n",
    "                # Convert transcript to phoneme tokens\n",
    "                phonemes = g2p_(transcript, language)\n",
    "                phonemeStr = phonemes[0]\n",
    "\n",
    "                checkPhonemeList(phonemeStr.split('|'))\n",
    "\n",
    "                phoneme_ids = phoneme2token(phonemeStr) # Phoneme IDs\n",
    "                # Extract semantic codes\n",
    "                semantic_code = extract_semantic_code(semantic_mean, semantic_std, speech_16k)\n",
    "                # Save semantic code as .npy file\n",
    "                semantic_code_filename = os.path.basename(audio_path).replace('.wav', '.npy').replace('.mp3', '.npy')\n",
    "                semantic_code_path = os.path.join(output_dir, semantic_code_filename)\n",
    "                np.save(semantic_code_path, semantic_code)\n",
    "                # Write to CSV\n",
    "                csv_writer.writerow([phoneme_ids, semantic_code_path])\n",
    "\n",
    "    print(\"Dataset preparation completed.\")\n",
    "\n",
    "# Usage\n",
    "#input_text_file = DatasetDir + 'dataset.txt'  # Replace with your input text file path\n",
    "output_csv_file = DatasetDir + 'prepared_data.csv'  # Output CSV file\n",
    "output_dir = DatasetDir + 'semantic_codes'  # Directory to save semantic code .npy files\n",
    "\n",
    "prepare_dataset(input_text_file, output_csv_file, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf5566f-950e-4490-9f93-efbf90bc13c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de8c0d6-bdcc-4def-82a8-69a82cf25ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "# Anyone else should probably change this to 0 if they only have one GPU. \n",
    "# We're only putting it on our secondary GPU since it has alot of VRAM. Training this thing takes ALOT of VRAM.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import ast  # For safely evaluating strings of lists\n",
    "import safetensors\n",
    "from utils.util import load_config\n",
    "from pytorch_optimizer import AdamW\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from maskgct_t2s import MaskGCT_T2S\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "###########  ------------------\n",
    "\n",
    "padding_token = 0  # Adjust if a different padding token is used\n",
    "model_type = \"t2s_model\"\n",
    "ckptDir = f\"./ckpt/MaskGCT/{model_type}/\"\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 700\n",
    "batchSize = 1  #looks like it might only be trained like this...\n",
    "warmup_steps = 100  # is it a good idea to copy F5-TTS on this? who knows!\n",
    "# -------------------\n",
    "\n",
    "# Initialize necessary models and processors\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Load semantic codec\n",
    "cfg_path = \"./maskgct/config/maskgct.json\"\n",
    "cfg = load_config(cfg_path)\n",
    "\n",
    "\n",
    "\n",
    "class T2SDataset(Dataset):\n",
    "    def __init__(self, csv_file, max_semantic_length=11600):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): Path to the CSV file with phoneme IDs and semantic code paths.\n",
    "            max_semantic_length (int): Maximum allowed length for the semantic code sequence.\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.max_semantic_length = max_semantic_length\n",
    "\n",
    "        # Pre-load data and filter out samples that exceed the maximum length\n",
    "        self.filtered_data = []\n",
    "        for _, row in self.data.iterrows():\n",
    "            phoneme_ids = ast.literal_eval(row['phoneme_ids'])\n",
    "            semantic_code_path = row['semantic_code_path']\n",
    "\n",
    "            # Load semantic code\n",
    "            if os.path.exists(semantic_code_path):\n",
    "                semantic_code = np.load(semantic_code_path)\n",
    "                if len(semantic_code) <= self.max_semantic_length:\n",
    "                    # Append valid sample to filtered data\n",
    "                    self.filtered_data.append(\n",
    "                        {\n",
    "                            'phoneme_ids': phoneme_ids,\n",
    "                            'semantic_code': semantic_code\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filtered_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve the pre-loaded data\n",
    "        sample = self.filtered_data[idx]\n",
    "        phoneme_ids = torch.tensor(sample['phoneme_ids'], dtype=torch.long)\n",
    "        semantic_code = torch.tensor(sample['semantic_code'], dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            'phoneme_ids': phoneme_ids,\n",
    "            'semantic_code': semantic_code\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    #batch = [item for item in batch if item is not None]\n",
    "    # Extract phoneme_ids and semantic_code from each item\n",
    "    phoneme_ids = [item['phoneme_ids'] for item in batch]\n",
    "    semantic_codes = [item['semantic_code'] for item in batch]\n",
    "\n",
    "    # Pad sequences\n",
    "    phoneme_ids_padded = torch.nn.utils.rnn.pad_sequence(\n",
    "        phoneme_ids, batch_first=True, padding_value=1023  # Padding index for phoneme IDs\n",
    "    )\n",
    "    semantic_codes_padded = torch.nn.utils.rnn.pad_sequence(\n",
    "        semantic_codes, batch_first=True, padding_value=-1  # Padding index for semantic codes\n",
    "    )\n",
    "\n",
    "    # Create masks\n",
    "    phone_mask = (phoneme_ids_padded != 1023).long()\n",
    "    semantic_mask = (semantic_codes_padded != -1).long()\n",
    "\n",
    "    return {\n",
    "        'phone_ids': phoneme_ids_padded,\n",
    "        'phone_mask': phone_mask,\n",
    "        'semantic_code': semantic_codes_padded,\n",
    "        'semantic_mask': semantic_mask\n",
    "    }\n",
    "\n",
    "\n",
    "# Usage\n",
    "csv_file = './dataset/prepared_data.csv'  # Path to your CSV file\n",
    "\n",
    "\n",
    "# Training loop\n",
    "\n",
    "# Initialize model\n",
    "cfg = load_config(cfg_path).model.t2s_model\n",
    "model = MaskGCT_T2S(cfg=cfg).to(device)\n",
    "\n",
    "CodeBookSize = cfg.cond_codebook_size\n",
    "\n",
    "print(cfg)\n",
    "# Define optimizer and loss function\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-5,\n",
    ")# Yeah just put the optimizer you pick here\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Adjust ignore_index as needed\n",
    "\n",
    "\n",
    "# Define the loss function with reduction='none' since we'll compute loss manually\n",
    "#criterion = torch.nn.KLDivLoss(reduction='none')\n",
    "\n",
    "\n",
    "\n",
    "checkpoints = [f for f in os.listdir(ckptDir) if f.endswith('.pt')]\n",
    "if checkpoints:\n",
    "    ckpt_path = sorted(checkpoints, key=lambda x: os.path.getmtime( os.path.join(ckptDir,x )))[-1]\n",
    "else:\n",
    "    ckpt_path = \"origmodel.safetensors\"\n",
    "ckpt_path = os.path.join(ckptDir, ckpt_path)\n",
    "print(ckpt_path)\n",
    "\n",
    "\n",
    "ckpt_type = ckpt_path.split(\".\")[-1]\n",
    "if ckpt_type == \"safetensors\":\n",
    "    checkpoint = load_file(ckpt_path, device=\"cuda\")\n",
    "    model.load_state_dict(checkpoint)\n",
    "else:\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device, weights_only=True)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['opt'])    \n",
    "# Load pre-trained weights into the model\n",
    "#safetensors.torch.load_model(model, ckpt_path)\n",
    "\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = T2SDataset(csv_file)\n",
    "dataloader = DataLoader(dataset, batch_size=batchSize, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "step = 0\n",
    "\n",
    "\n",
    "total_steps = len(dataloader) * num_epochs\n",
    "decay_steps = total_steps - warmup_steps\n",
    "\n",
    "warmup_scheduler = LinearLR(optimizer, start_factor=1e-8, end_factor=1.0, total_iters=warmup_steps)\n",
    "decay_scheduler = LinearLR(optimizer, start_factor=1.0, end_factor=1e-8, total_iters=decay_steps)\n",
    "\n",
    "scheduler = SequentialLR(optimizer, schedulers=[warmup_scheduler, decay_scheduler], milestones=[warmup_steps])\n",
    "\n",
    "\n",
    "progress_bar = tqdm(dataloader, unit=\"step\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move data to device\n",
    "        x0 = batch['semantic_code'].to(device)\n",
    "        x_mask = batch['semantic_mask'].to(device)\n",
    "        phone_ids = batch['phone_ids'].to(device)\n",
    "        phone_mask = batch['phone_mask'].to(device)\n",
    "\n",
    "        # Ohh you need the x_mask and phone_mask for batches and ignoring padded tokens! RIGHT!\n",
    "        \n",
    "        # Forward pass\n",
    "        logits, final_mask, _, prompt_len, mask_prob = model(\n",
    "            x0, x_mask, phone_ids, phone_mask\n",
    "        )\n",
    "\n",
    "        ## Prepare the final mask\n",
    "        #final_mask = final_mask.squeeze(-1)  # Shape: (B, T)\n",
    "        ## Flatten the final mask\n",
    "        #final_mask_flat = final_mask.view(-1)  # Shape: (B*T,)\n",
    "        ## Flatten targets\n",
    "        #targets_flat = x0_targets.view(-1)  # Shape: (B*T,)\n",
    "        ## Compute model's predicted distribution p_probs\n",
    "        #logits_flat = logits.view(-1, logits.size(-1))  # Shape: (B*T, vocab_size)\n",
    "        #p_probs_flat = F.log_softmax(logits_flat, dim=-1)  # Log probabilities for KLDivLoss\n",
    "        ## Compute true distribution q_probs as one-hot vectors over x0_targets\n",
    "        #vocab_size = logits.size(-1)\n",
    "        #q_probs_flat = torch.zeros_like(p_probs_flat)  # Shape: (B*T, vocab_size)\n",
    "        #q_probs_flat.scatter_(1, targets_flat.unsqueeze(1), 1.0)  # One-hot encoding\n",
    "        ## Compute KL divergence only over masked positions\n",
    "        ## Masked positions have final_mask_flat == 1\n",
    "        #kl_div = criterion(p_probs_flat, q_probs_flat).sum(dim=1)  # Shape: (B*T,)\n",
    "        ## Apply the final mask\n",
    "        #kl_div = kl_div * final_mask_flat  # Zero out unmasked positions\n",
    "        ## Compute average loss\n",
    "        #loss = kl_div.sum() / final_mask_flat.sum()\n",
    "\n",
    "        #use reshape to flatten tensors\n",
    "        #print(x0.shape)\n",
    "        logits_flat = logits.reshape(-1, CodeBookSize)\n",
    "        #print(logits_flat.shape)\n",
    "        x0_flat = x0.reshape(-1)\n",
    "        final_mask = final_mask.reshape(-1)\n",
    "        #print(final_mask)\n",
    "        #mask out the losses\n",
    "        logits_flat = logits_flat[final_mask > 0]\n",
    "        x0_flat = x0_flat[final_mask > 0]\n",
    "        #print(logits_flat)\n",
    "        # Compute the loss only over masked positions\n",
    "        loss = criterion(logits_flat, x0_flat)\n",
    "        #loss = torch.nn.functional.cross_entropy(logits_flat, x0_flat, reduction='none')\n",
    "        #loss = loss.view(x0_targets.size()) \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        step += 1\n",
    "        \n",
    "        total_loss += loss.detach().item()\n",
    "        progress_bar.set_postfix(step=str(step), loss=loss.detach().item())\n",
    "        #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.detach().item()}\")\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}\")\n",
    "\n",
    "    # Optionally, save the model checkpoint\n",
    "    #torch.save(model.state_dict(), f'maskgct_t2s_epoch{epoch+1}.pth')\n",
    "\n",
    "    # Save model and optimizer state dictionaries\n",
    "    if (epoch + 1) % 10 == 0:  # Save every 10 epochs\n",
    "        torch.save({\n",
    "            #'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'opt': optimizer.state_dict(),\n",
    "            #'loss': loss,\n",
    "        }, ckptDir + 'newT2S_epoch{}.pt'.format(epoch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6156bb-8cea-4b83-bb2a-8b40355bc604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below is just debug and experimental.... pretty much this whole thing is debug and experimental\n",
    "\n",
    "# This is not meant to be user friendly. No time, no resources. Busy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06632bb2-3638-43b1-b104-2664992dd51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_probs_flat.shape)\n",
    "print(q_probs_flat.shape)\n",
    "print(criterion(p_probs_flat, q_probs_flat).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa39b9-1f3b-4cfe-842d-93afbcc46246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_statistics(dataset):\n",
    "    phoneme_lengths = []\n",
    "    semantic_code_lengths = []\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        sample = dataset[i]\n",
    "        phoneme_lengths.append(len(sample['phoneme_ids']))\n",
    "        semantic_code_lengths.append(len(sample['semantic_code']))\n",
    "\n",
    "    # Convert lists to numpy arrays for easier statistical calculations\n",
    "    phoneme_lengths = np.array(phoneme_lengths)\n",
    "    semantic_code_lengths = np.array(semantic_code_lengths)\n",
    "\n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        'phoneme_lengths': {\n",
    "            'max': phoneme_lengths.max(),\n",
    "            'min': phoneme_lengths.min(),\n",
    "            'mean': phoneme_lengths.mean(),\n",
    "            'median': np.median(phoneme_lengths),\n",
    "            'std': phoneme_lengths.std(),\n",
    "        },\n",
    "        'semantic_code_lengths': {\n",
    "            'max': semantic_code_lengths.max(),\n",
    "            'min': semantic_code_lengths.min(),\n",
    "            'mean': semantic_code_lengths.mean(),\n",
    "            'median': np.median(semantic_code_lengths),\n",
    "            'std': semantic_code_lengths.std(),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Find the longest entry\n",
    "    longest_phoneme_idx = phoneme_lengths.argmax()\n",
    "    longest_phoneme_sample = dataset[longest_phoneme_idx]\n",
    "    longest_semantic_idx = semantic_code_lengths.argmax()\n",
    "    longest_semantic_sample = dataset[longest_semantic_idx]\n",
    "\n",
    "    return stats, longest_phoneme_sample, longest_semantic_sample\n",
    "\n",
    "# Get statistics and longest entries\n",
    "stats, longest_phoneme_sample, longest_semantic_sample = get_dataset_statistics(dataset)\n",
    "\n",
    "print(\"Statistics:\")\n",
    "print(stats)\n",
    "\n",
    "print(\"\\nLongest phoneme sequence:\")\n",
    "print(\"Length:\", len(longest_phoneme_sample['phoneme_ids']))\n",
    "print(\"Phoneme IDs:\", longest_phoneme_sample['phoneme_ids'])\n",
    "\n",
    "print(\"\\nLongest semantic code sequence:\")\n",
    "print(\"Length:\", len(longest_semantic_sample['semantic_code']))\n",
    "print(\"Semantic Codes:\", longest_semantic_sample['semantic_code'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5786530-ffb5-4026-aac3-e59cb54bcf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from safetensors.torch import save_file\n",
    "\n",
    "model_type = \"t2s_model\"\n",
    "ckptDir = f\"./ckpt/MaskGCT/{model_type}/\"\n",
    "\n",
    "checkpoints = [f for f in os.listdir(ckptDir) if f.endswith('.pt')]\n",
    "if checkpoints:\n",
    "    ckpt_path = sorted(checkpoints, key=lambda x: os.path.getmtime( os.path.join(ckptDir,x )))[-1]\n",
    "else:\n",
    "    ckpt_path = \"origmodel.safetensors\"\n",
    "ckpt_path = os.path.join(ckptDir, ckpt_path)\n",
    "print(ckpt_path)\n",
    "checkpoint = torch.load(ckpt_path, map_location='cpu')\n",
    "# Assuming the checkpoint contains a 'state_dict'\n",
    "state_dict = checkpoint['model'] if 'model' in checkpoint else checkpoint\n",
    "# Save the state dictionary to .safetensors format\n",
    "save_file(state_dict, ckptDir + 'model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a35e0-ea43-45d8-8586-3d071bce84d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e74e2-892d-45b0-be7f-dc2353d77a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(state_dict['model'], ckptDir + 'model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c048b3-7710-4913-9082-8aad71753939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
